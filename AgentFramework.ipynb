{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ffcd35b",
   "metadata": {},
   "source": [
    "# Microsoft Agent Framework Samples\n",
    "\n",
    "Microsoft Agent Framework は、 .NET および Python 向けの AI エージェントおよびマルチエージェント ワークフロー を構築するためのオープンソース開発キットです。Semantic Kernel プロジェクト と AutoGen プロジェクト のアイデアを統合・拡張し、それぞれの長所を組み合わせながら新しい機能も追加しています。同じチームによって構築されたこのフレームワークは、今後の AI エージェント構築のための統一された基盤となります。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cae4dd",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cb2ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install agent-framework --pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfaa14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework.openai import OpenAIChatClient\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "deployment_name = os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"]\n",
    "api_key = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "\n",
    "client = AzureOpenAIChatClient(\n",
    "    deployment_name=deployment_name,\n",
    "    endpoint=endpoint,\n",
    "    api_key=api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d5308",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d40452",
   "metadata": {},
   "source": [
    "詳細な例については、以下を参照してください：\n",
    "\n",
    "- [OpenAI Chat Client](https://github.com/microsoft/agent-framework/blob/main/python/samples/getting_started/agents/openai/openai_chat_client_basic.py) - Basic OpenAI client setup\n",
    "- [Azure OpenAI Chat Client](https://github.com/microsoft/agent-framework/blob/main/python/samples/getting_started/agents/azure_openai/azure_chat_client_basic.py) - Azure OpenAI with authentication\n",
    "- [Azure AI Client](https://github.com/microsoft/agent-framework/blob/main/python/samples/getting_started/agents/azure_ai/azure_ai_basic.py) - Azure AI agent integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc37ae76",
   "metadata": {},
   "source": [
    "## Responses API Support\n",
    "Agent Framework の `AzureOpenAIResponsesClient` および `OpenAIResponsesClient` は、AutoGen では利用できない推論モデルと構造化応答に対する専用サポートを提供します："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2257ca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework.azure import AzureOpenAIResponsesClient\n",
    "from agent_framework.openai import OpenAIResponsesClient\n",
    "\n",
    "# Azure OpenAI with Responses API\n",
    "azure_responses_client = AzureOpenAIResponsesClient(model_id=\"gpt-5\")\n",
    "\n",
    "# OpenAI with Responses API\n",
    "# openai_responses_client = OpenAIResponsesClient(model_id=\"gpt-5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0125c23",
   "metadata": {},
   "source": [
    "Responses API の例については、以下を参照してください：\n",
    "\n",
    "- [Azure Responses Client Basic](https://github.com/microsoft/agent-framework/blob/main/python/samples/getting_started/agents/azure_openai/azure_responses_client_basic.py) - Azure OpenAI with responses\n",
    "- [OpenAI Responses Client Basic](https://github.com/microsoft/agent-framework/blob/main/python/samples/getting_started/agents/openai/openai_responses_client_basic.py) - OpenAI responses integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b7ed74",
   "metadata": {},
   "source": [
    "## Observability\n",
    "可観測性は、ワークフロー実行時の内部状態と動作に関する洞察を提供します。これには、ワークフローの監視とデバッグに役立つログ、メトリクス、トレース機能が含まれます。Agent Framework は OpenTelemetry のよりシンプルなゼロコードセットアップオプションを提供します。これによりすでに紹介した [Jaeger](https://qiita.com/nohanaga/items/6e0a42716e86eea58091) や [Azure AI Foundry](https://qiita.com/nohanaga/items/098d2bbdecac69bb3923) との連携による監視がより簡単にできるようになりました。さらにワークフローレベルの観測可能性を含むより広範なカバレッジを提供します。\n",
    "\n",
    "エージェントのトレースはマルチエージェント開発には必須の機能と言っても過言ではないです。私のワークショップでも最初にトレースの設定を行います。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70fa2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework.observability import setup_observability\n",
    "\n",
    "setup_observability(\n",
    "    enable_sensitive_data=True,\n",
    "    otlp_endpoint=\"http://localhost:4317\",\n",
    "    # applicationinsights_connection_string=\"InstrumentationKey=your_key\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccefe62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework.observability import get_tracer, get_meter\n",
    "\n",
    "tracer = get_tracer()\n",
    "meter = get_meter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2ab8a9",
   "metadata": {},
   "source": [
    "## Agent Hello World!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659dce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import ChatAgent\n",
    "# Agent Framework\n",
    "with tracer.start_as_current_span(\"HelloWorld\") as rollspan: # ルートスパンを作成\n",
    "\n",
    "    agent = ChatAgent(name=\"assistant\", chat_client=client)\n",
    "    result = await agent.run(\"富士山の高さは?\")\n",
    "\n",
    "    print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac386da",
   "metadata": {},
   "source": [
    "## ⭐️ AgentThread による会話状態の管理\n",
    "単一エージェントの対話はステートレスです。`ChatAgent` との会話を続けるには、 `AgentThread` を使用して会話履歴を管理できるようになりました。これが最も基本的なコンテキスト共有の仕組みです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40f180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"HelloWorld\") as rollspan: # ルートスパンを作成\n",
    "\n",
    "    # スレッドなし（2つの独立した呼び出し）\n",
    "    r1 = await agent.run(\"2+2は?\")\n",
    "    print(r1.text)  # e.g., \"4\"\n",
    "\n",
    "    r2 = await agent.run(\"その数字に10を掛けるとどうなる？\")\n",
    "    print(r2.text)  # コンテキストがなければ曖昧な可能性あり；「40」とは限らない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6926514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"HelloWorld\") as rollspan: # ルートスパンを作成\n",
    "\n",
    "    # スレッドを使用（呼び出し間で共有されるコンテキスト）\n",
    "    thread = agent.get_new_thread()\n",
    "    print((await agent.run(\"2+2は?\", thread=thread)).text)  # \"4\"\n",
    "    print((await agent.run(\"その数字に10を掛けるとどうなる？\", thread=thread)).text)  # \"40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e34445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# メッセージの内容を詳しく見てみる\n",
    "messages = await thread.message_store.list_messages()\n",
    "print(f\"メッセージ数: {len(messages)}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, msg in enumerate(messages):\n",
    "    print(f\"メッセージ {i + 1}:\")\n",
    "    print(f\"  役割: {msg.role}\")\n",
    "    print(f\"  テキスト: {msg.text}\")\n",
    "    print(f\"  オブジェクト: {msg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9611f239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, pprint\n",
    "# Serialize thread state\n",
    "serialized_thread = await thread.serialize()\n",
    "\n",
    "pprint.pprint(serialized_thread)\n",
    "# Save to file/database\n",
    "# with open(\"thread_state.json\", \"w\") as f:\n",
    "#     json.dump(serialized_thread, f) # 現状 ChatMessage オブジェクトのエラーが出てしまいます"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7ee9e0",
   "metadata": {},
   "source": [
    "## Tool Creation and Integration\n",
    "ツールはテキスト生成を超えてエージェントの機能を拡張します。フレームワークはツール作成において異なるアプローチを取っており、Agent Framework はより自動化されたスキーマ生成を提供します。\n",
    "\n",
    "Agent Framework は、エージェントレベルでツールの反復処理を自動で行います。AutoGen の`max_tool_iterations` パラメータとは異なり、Agent Framework のエージェントは、無限ループを防ぐための安全機構を組み込んでおり、デフォルトで完了までツールの実行を継続します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f217875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import ai_function\n",
    "from typing import Annotated\n",
    "from pydantic import Field\n",
    "\n",
    "@ai_function\n",
    "def get_weather(\n",
    "    location: Annotated[str, Field(description=\"天気情報を入手するための場所を指定します\")]\n",
    ") -> str:\n",
    "    \"\"\"場所の天気情報を取得する。\"\"\"\n",
    "    return f\"Weather in {location}: rain\"\n",
    "\n",
    "# Direct use with agent (automatic conversion)\n",
    "agent = ChatAgent(name=\"assistant\", chat_client=client, tools=[get_weather])\n",
    "\n",
    "with tracer.start_as_current_span(\"Tool1\") as rollspan: # ルートスパンを作成\n",
    "    # スレッドなし（2つの独立した呼び出し）\n",
    "    response = await agent.run(\"東京の今日の天気は?\")\n",
    "    print(response)  # e.g., \"4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3c8e6c",
   "metadata": {},
   "source": [
    "## Hosted Tools\n",
    "Agent Framework は、AutoGen では利用できないホスト ツールを提供します。ホスト型ツールは、それらをサポートするモデル/アカウントでのみ利用できます。これらのツールを有効にする前に、プロバイダーの権限とモデルサポートを確認してください。以下は Azure AI Foundry Agent との連携。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b35556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import ChatAgent, HostedCodeInterpreterTool, HostedWebSearchTool\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "\n",
    "# Code execution tool\n",
    "code_tool = HostedCodeInterpreterTool()\n",
    "\n",
    "# Web search tool\n",
    "search_tool = HostedWebSearchTool()\n",
    "\n",
    "agent = ChatAgent(\n",
    "    name=\"researcher\",\n",
    "    chat_client=client,\n",
    "    tools=[code_tool, search_tool]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613a9d6a",
   "metadata": {},
   "source": [
    "主な違い:\n",
    "- デフォルト動作: ChatAgentはツール呼び出しを自動的に反復処理しますが、AssistantAgentは明示的なmax_tool_iterations設定が必要です\n",
    "- 実行時設定: ChatAgent.run()は呼び出しごとのカスタマイズ用にtoolsおよびtool_choiceパラメータを受け付けます\n",
    "- ファクトリメソッド: Agent Frameworkはチャットクライアントから直接便利なファクトリメソッドを提供します\n",
    "- 状態管理: ChatAgentはステートレスであり、呼び出し間の会話履歴を維持しません。これに対しAssistantAgentは状態の一部として会話履歴を維持します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e13473",
   "metadata": {},
   "source": [
    "詳細な例については以下を参照してください:\n",
    "- [Azure AI with Code Interpreter](https://github.com/microsoft/agent-framework/blob/main/python/samples/getting_started/agents/azure_ai/azure_ai_with_code_interpreter.py) - コード実行ツール\n",
    "- [Azure AI with Multiple Tools](https://github.com/microsoft/agent-framework/blob/main/python/samples/getting_started/agents/azure_ai/azure_ai_with_multiple_tools.py) - 複数ホスト型ツール\n",
    "- [OpenAI with Web Search](https://github.com/microsoft/agent-framework/blob/main/python/samples/getting_started/agents/openai/openai_chat_client_with_web_search.py) - Web検索統合\n",
    "\n",
    "要件と注意点:\n",
    "- ホスト型ツールは、それらをサポートするモデル/アカウントでのみ利用可能です。これらのツールを有効化する前に、プロバイダーの権限とモデルサポートを確認してください。\n",
    "- プロバイダーごとに設定が異なります。セットアップと権限設定については、各サンプルの事前準備要件に従ってください。\n",
    "- すべてのモデルがすべてのホスト型ツール（例: Web 検索とコード インタープリター）をサポートするわけではありません。環境で互換性のあるモデルを選択してください。\n",
    "\n",
    "注記: AutoGen はローカルコード実行ツールをサポートしていますが、この機能は将来の Agent Framework バージョンで提供予定です。\n",
    "\n",
    "主な違い: Agent Framework はエージェントレベルでツール反復処理を自動的に処理します。AutoGen の max_tool_iterations パラメータとは異なり、Agent Framework エージェントはデフォルトでツール実行を完了まで継続し、無限ループを防ぐ組み込みの安全メカニズムを備えています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da36483d",
   "metadata": {},
   "source": [
    "## MCP Server Support\n",
    "高度なツール統合のため、両フレームワークはモデルコンテキストプロトコル（MCP）をサポートし、エージェントが外部サービスやデータソースと相互作用することを可能にします。Agent Framework はより包括的な組み込みサポートを提供します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276e1208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import ChatAgent, MCPStdioTool, MCPStreamableHTTPTool, MCPWebsocketTool\n",
    "\n",
    "# Stdio MCP server\n",
    "mcp_tool = MCPStdioTool(\n",
    "    name=\"filesystem\",\n",
    "    command=\"uvx mcp-server-filesystem\",\n",
    "    args=[\"/allowed/directory\"]\n",
    ")\n",
    "\n",
    "# HTTP streaming MCP\n",
    "http_mcp = MCPStreamableHTTPTool(\n",
    "    name=\"http_mcp\",\n",
    "    url=\"https://learn.microsoft.com/api/mcp\"\n",
    ")\n",
    "\n",
    "# WebSocket MCP\n",
    "ws_mcp = MCPWebsocketTool(\n",
    "    name=\"websocket_mcp\",\n",
    "    url=\"ws://localhost:8000/ws\"\n",
    ")\n",
    "\n",
    "agent = ChatAgent(name=\"assistant\", chat_client=client, tools=[http_mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed235b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"MCPChat\") as rollspan: # ルートスパンを作成\n",
    "    # Without a thread (two independent invocations)\n",
    "    response = await agent.run(\"Azure AI Search の2025年の最新のニュースを教えてください\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763710f3",
   "metadata": {},
   "source": [
    "詳細な例については、以下を参照してください：\n",
    "\n",
    "- [ローカルMCPを使用したOpenAI](https://github.com/microsoft/agent-framework/blob/main/python/samples/getting_started/agents/openai/openai_chat_client_with_local_mcp.py) - OpenAIでMCPStreamableHTTPToolを使用する\n",
    "- [ホスト型MCPを使用したOpenAI](https://github.com/microsoft/agent-framework/blob/main/python/samples/getting_started/agents/openai/openai_responses_client_with_hosted_mcp.py) - ホスト型MCPサービスを使用する\n",
    "- [ローカルMCPを使用したAzure AI](https://github.com/microsoft/agent-framework/blob/main/python/samples/getting_started/agents/azure_ai/azure_ai_with_local_mcp.py) - Azure AIでMCPを使用する\n",
    "- [ホスト型MCPを使用したAzure AI](https://github.com/microsoft/agent-framework/blob/main/python/samples/getting_started/agents/azure_ai/azure_ai_with_hosted_mcp.py) - Azure AIでホスト型MCPを使用する\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c044ad87",
   "metadata": {},
   "source": [
    "## Agent-as-a-Tool Pattern\n",
    "新たなマルチエージェントの強力なパターンの一つは、エージェント自体をツールとして使用し、階層的なエージェントアーキテクチャを実現することです。シンプルなマルチエージェントパターンを実装したい場合は、この機能で実現できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f71fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import ChatAgent\n",
    "\n",
    "# Create specialized agent\n",
    "writer = ChatAgent(\n",
    "    name=\"writer\",\n",
    "    chat_client=client,\n",
    "    instructions=\"あなたは創造的で破天荒な作家です。\"\n",
    ")\n",
    "\n",
    "# Convert to tool\n",
    "writer_tool = writer.as_tool(\n",
    "    name=\"creative_writer\",\n",
    "    description=\"創造的なコンテンツを生成する\",\n",
    "    arg_name=\"request\",\n",
    "    arg_description=\"何を書くか\"\n",
    ")\n",
    "\n",
    "# Use in coordinator\n",
    "coordinator = ChatAgent(\n",
    "    name=\"coordinator\",\n",
    "    chat_client=client,\n",
    "    tools=[writer_tool]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0120db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"Agent-as-a-Tool\") as rollspan: # ルートスパンを作成\n",
    "    # Without a thread (two independent invocations)\n",
    "    response = await coordinator.run(\"SEが異世界に転生して無双する話を書いてください\")\n",
    "    print(response.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d2ffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = response.to_dict()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5ee17c",
   "metadata": {},
   "source": [
    "## Middleware (Agent Framework Feature)\n",
    "Agent FrameworkはAutoGenに欠けているミドルウェア機能を導入します。ミドルウェアにより、ロギング、セキュリティ、パフォーマンス監視といった強力な横断的関心事の処理が可能になります。\n",
    "\n",
    "以下の `security_middleware` の例は関数呼び出しの引数に\"password\"が含まれている場合に実行をブロックします。以下のテストでこの動作を確認できます：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792afb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import ChatAgent, AgentRunContext, FunctionInvocationContext\n",
    "from typing import Callable, Awaitable\n",
    "# パターン1: 直接的にパスワードを含む引数でツールを呼び出す\n",
    "\n",
    "# 以前の例からクライアントがあると仮定する\n",
    "async def logging_middleware(\n",
    "    context: AgentRunContext,\n",
    "    next: Callable[[AgentRunContext], Awaitable[None]]\n",
    ") -> None:\n",
    "    print(f\"Agent {context.agent.name} starting\")\n",
    "    await next(context)\n",
    "    print(f\"Agent {context.agent.name} completed\")\n",
    "\n",
    "async def security_middleware(\n",
    "    context: FunctionInvocationContext,\n",
    "    next: Callable[[FunctionInvocationContext], Awaitable[None]]\n",
    ") -> None:\n",
    "    if \"password\" in str(context.arguments):\n",
    "        print(\"機密データを含む関数呼び出しのブロック\")\n",
    "        return  # Don't call next()\n",
    "    await next(context)\n",
    "\n",
    "@ai_function\n",
    "def test_security_function(input_text: str) -> str:\n",
    "    \"\"\"テスト用の関数\"\"\"\n",
    "    return f\"処理結果: {input_text}\"\n",
    "\n",
    "# セキュリティミドルウェア付きのエージェントを作成\n",
    "secure_agent = ChatAgent(\n",
    "    name=\"secure_test_agent\",\n",
    "    chat_client=client,\n",
    "    middleware=[logging_middleware, security_middleware],\n",
    "    tools=[test_security_function]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d354363",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== テスト1: 直接的なパスワード文字列 ===\")\n",
    "try:\n",
    "    result = await secure_agent.run(\"test_security_functionを使って 'my password is 123' を処理してください\")\n",
    "    print(f\"結果: {result.text}\")\n",
    "except Exception as e:\n",
    "    print(f\"エラー: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2e91ef",
   "metadata": {},
   "source": [
    "利点:\n",
    "- セキュリティ: 入力検証とコンテンツフィルタリング\n",
    "- 可観測性: ログ記録、メトリクス、トレース\n",
    "- パフォーマンス: キャッシュとレート制限\n",
    "- エラー処理: 段階的劣化と再試行ロジック\n",
    "\n",
    "詳細なミドルウェアの例については以下を参照:\n",
    "- [関数ベースのミドルウェア](https://github.com/microsoft/agent-framework/blob/main/python/samples/getting_started/middleware/function_based_middleware.py) - シンプルな関数ミドルウェア\n",
    "- [クラスベースのミドルウェア](https://github.com/microsoft/agent-framework/blob/main/python/samples/getting_started/middleware/class_based_middleware.py) - オブジェクト指向ミドルウェア\n",
    "- [例外処理ミドルウェア](https://github.com/microsoft/agent-framework/blob/main/python/samples/getting_started/middleware/exception_handling_with_middleware.py) - エラー処理パターン\n",
    "- [共有状態ミドルウェア](https://github.com/microsoft/agent-framework/blob/main/python/samples/getting_started/middleware/shared_state_middleware.py) - エージェント間での状態管理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67260c36",
   "metadata": {},
   "source": [
    "\n",
    "## Memory\n",
    "エージェントメモリは、エージェントが会話間でコンテキストを維持し、ユーザーの好みを記憶し、パーソナライズされた体験を提供するための重要な機能です。エージェントフレームワークは、単純なインメモリストレージから永続データベース、専用メモリサービスに至るまで、様々なユースケースに対応する複数のメモリ機構を提供します。\n",
    "\n",
    "### Memory の種類\n",
    "エージェントフレームワークは、短期記憶の一部としてチャット履歴を管理したり、長期記憶を抽出して保存しエージェントに注入するための拡張ポイントを提供したりするなど、様々なユースケースに対応するため、複数のメモリタイプをサポートしています。\n",
    "\n",
    "- In-Memory Storage (Default): チャットスレッドのこと\n",
    "- Persistent Message Stores\n",
    "    - Built-in ChatMessageStore\n",
    "    - Redis Message Store\n",
    "    - Custom Message Store\n",
    "- Context Providers (Dynamic Memory)\n",
    "    - External Memory Services(Mem0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bedd9d3",
   "metadata": {},
   "source": [
    "\n",
    "### Persistent Message Stores\n",
    "セッション間で会話履歴を保持する必要のあるアプリケーションの場合、`ChatMessageStore` フレームワークは次の実装を提供します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54bbed7",
   "metadata": {},
   "source": [
    "### 組み込みの ChatMessageStore\n",
    "シリアライズ可能なデフォルトのインメモリ実装です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fcd03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import ChatMessageStore, ChatAgent, AgentThread\n",
    "\n",
    "# 方法1: スレッドから message_store を取得する\n",
    "def create_message_store():\n",
    "    return ChatMessageStore()\n",
    "\n",
    "agent = ChatAgent(\n",
    "    chat_client=client,\n",
    "    instructions=\"You are a helpful travel assistant.\",\n",
    "    chat_message_store_factory=create_message_store\n",
    ")\n",
    "\n",
    "# スレッドを作成（この時点で新しいストアが作成される）\n",
    "thread = agent.get_new_thread()\n",
    "\n",
    "response = await agent.run(\"マレーシア行きの飛行機の予約をしてもらえますか？\", thread=thread)\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7164d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# スレッドから message_store を取得\n",
    "if thread.message_store:\n",
    "    messages = await thread.message_store.list_messages()\n",
    "    print(\"\\n=== 会話履歴 ===\")\n",
    "    for msg in messages:\n",
    "        print(f\"{msg.role}: {msg.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf87a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# スレッドの状態をシリアル化して、後で使用できるように保存できるようにする。\n",
    "serialized_thread = await thread.serialize()\n",
    "\n",
    "# スレッドはデータベース、ファイル、または他のストレージメカニズムに保存でき、後で再度読み込むことができる。\n",
    "print(f\"Serialized thread: {serialized_thread}\\n\")\n",
    "\n",
    "# ストレージから読み込んだ後にスレッドの状態をデシリアライズする。\n",
    "resumed_thread = await agent.deserialize_thread(serialized_thread)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879813ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# メッセージの内容を詳しく見てみる\n",
    "messages = await resumed_thread.message_store.list_messages()\n",
    "print(f\"メッセージ数: {len(messages)}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, msg in enumerate(messages):\n",
    "    print(f\"メッセージ {i + 1}:\")\n",
    "    print(f\"  役割: {msg.role}\")\n",
    "    print(f\"  テキスト: {msg.text}\")\n",
    "    print(f\"  オブジェクト: {msg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d78aee7",
   "metadata": {},
   "source": [
    "\n",
    "### Redis Message Store\n",
    "現在は永続ストレージとして Redis が指定できますが、今後は CosmosDB や Azure AI Search が追加されることでしょう。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3251e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework.redis import RedisChatMessageStore\n",
    "\n",
    "def create_redis_store():\n",
    "    return RedisChatMessageStore(\n",
    "        redis_url=\"redis://localhost:6379\",\n",
    "        thread_id=\"user_session_123\",\n",
    "        max_messages=100  # Keep last 100 messages\n",
    "    )\n",
    "\n",
    "agent = ChatAgent(\n",
    "    chat_client=OpenAIChatClient(),\n",
    "    instructions=\"You are a helpful assistant.\",\n",
    "    chat_message_store_factory=create_redis_store\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3842be03",
   "metadata": {},
   "source": [
    "## Context Providers (Dynamic Memory)\n",
    "コンテキスト プロバイダーは、各エージェントの呼び出しの前に関連するコンテキストを挿入することで、洗練されたメモリ パターンを実現します。メモリ設計については以下のスコープに分類できます。\n",
    "\n",
    "| スコープ | 説明 | ユースケース |\n",
    "|---------|------|------------|\n",
    "| **グローバル** | 全スレッドで共有 | ユーザープロファイル、基本設定 |\n",
    "| **スレッド単位** | スレッドごとに独立 | プロジェクト固有の情報 |\n",
    "| **エージェント単位** | エージェントごとに独立 | パーソナル/ビジネス コンテキストの分離 |\n",
    "\n",
    "\n",
    "### Mem0Provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2360d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework.mem0 import Mem0Provider\n",
    "\n",
    "# Using Mem0 for advanced memory capabilities\n",
    "memory_provider = Mem0Provider(\n",
    "    api_key=\"your-mem0-api-key\",\n",
    "    user_id=\"user_123\",\n",
    "    application_id=\"my_app\"\n",
    ")\n",
    "\n",
    "agent = ChatAgent(\n",
    "    chat_client=OpenAIChatClient(),\n",
    "    instructions=\"You are a helpful assistant with memory.\",\n",
    "    context_providers=memory_provider\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b325992",
   "metadata": {},
   "source": [
    "Mem0 についてはすでに Azure AI Search との連携を AutoGen で実現していましたね。メモリ機能についてはさらなる探究が必要です。\n",
    "\n",
    "https://qiita.com/nohanaga/items/37fbe8dfb35a506b1d5a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd683a57",
   "metadata": {},
   "source": [
    "# Multi-Agent Orchestration(WorkFlow)\n",
    "## AutoGen のマルチエージェントパターンの移行状況\n",
    "\n",
    "![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/674344/4d491a62-2ce2-43f2-a7b1-1427a4d49c64.png)\n",
    "\n",
    "\n",
    "AutoGen の課題:\n",
    "- 低レベルモデル（Core API）は多くのユーザーにとって複雑すぎる\n",
    "- 高レベルモデル（AgentChat API）は複雑な動作に対して制約となり得る\n",
    "- 両モデルの橋渡しは実装の複雑さを増す\n",
    "\n",
    "Agent Framework は、両方のアプローチの長所を組み合わせた単一のワークフロー抽象化を提供します。\n",
    "\n",
    "### GraphFlow vs WorkFlow\n",
    "Agent Framework のワークフロー抽象化は AutoGen の実験的機能 GraphFlow に着想を得ていますが、設計思想において重要な進化を遂げています。\n",
    "\n",
    "- **GraphFlow**：制御フローベース。エッジは遷移を表し、メッセージは全エージェントにブロードキャストされる。遷移はブロードキャストされたメッセージ内容によって条件付けられる\n",
    "- **WorkFlow**：データフローベース。メッセージは特定のエッジを経由してルーティングされ、エッジによって Executor が起動される。並行実行をサポートする。\n",
    "\n",
    "GraphFlow はエージェントを条件付き遷移とブロードキャストを持つノードとしてモデル化します。ワークフローは型付きエッジで接続された Executor（エージェント、関数、サブワークフロー）をモデル化し、リクエスト/レスポンスによる一時停止やチェックポイント機能もサポートします。\n",
    "\n",
    "| 観点 | AutoGen | Agent Framework|\n",
    "|------|----------------------|--------------------------------|\n",
    "| **基本パラダイム** | 制御フロー（GraphFlow） | データフロー（WorkFlow） |\n",
    "| **設計思想** | 「誰が次に話すか」を制御 | 「データがどこへ流れるか」を定義 |\n",
    "| **グラフの意味** | 実行順序の可能性を表現 | データの流れを表現 |\n",
    "| **エッジの役割** | 条件付き状態遷移 | 型付きデータパス |\n",
    "| **ノード種別** | エージェントのみ | エージェント + 関数 + サブワークフロー |\n",
    "| **メッセージ配信** | ブロードキャスト<br>(全ノードが全メッセージを受信) | ポイントツーポイント<br>(エッジで定義されたパスのみ) |\n",
    "\n",
    "https://qiita.com/nohanaga/items/60c66935d75d3dbc48e2\n",
    "\n",
    "AutoGen の制御フローをデータフローに変えてきたあたり、Microsoft らしいというか・・・Azure ML Pipeline や Prompt flow の系譜を感じざるを得ない。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab399df5",
   "metadata": {},
   "source": [
    "# ワークフロー基礎\n",
    "\n",
    "**WorkflowBuilder**\n",
    "- 汎用的で柔軟なワークフロー構築\n",
    "- ファンアウト/ファンイン、集約ロジックを明示的に実装\n",
    "- より細かい制御が可能\n",
    "\n",
    "**Concurrent/Sequential/Magentic Builder**\n",
    "- エージェント専用の簡潔な API\n",
    "- 内部的にディスパッチャーとアグリゲーターを自動生成\n",
    "- ボイラープレートコードが不要\n",
    "\n",
    "## 1. WorkflowBuilder\n",
    "### 1.1. Sequential + Conditional\n",
    "Agent Framework のワークフローのノード（Executor）はエージェント、純粋関数、またはサブワークフローとなり得ます。**注目は `add_edge` できるのがエージェントに限らない**という点ですね。Executor によって任意の関数を噛ませることができるというのと、メッセージの送信をコントロールできるという点が AutoGen と異なります。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e5a0ca",
   "metadata": {},
   "source": [
    "#### ワークフローの便利な可視化関数を先に定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484918c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import WorkflowViz\n",
    "from IPython.display import SVG, display\n",
    "import os\n",
    "\n",
    "def visualize_workflow(workflow, filename=\"workflow_diagram\", show_preview=True):\n",
    "    \"\"\"\n",
    "    ワークフローのグラフ情報を出力し、SVGで保存し、プレビューする関数\n",
    "    \n",
    "    Args:\n",
    "        workflow: 可視化するワークフローオブジェクト\n",
    "        filename: 保存するファイル名（拡張子なし）\n",
    "        show_preview: プレビューを表示するかどうか\n",
    "    \n",
    "    Returns:\n",
    "        保存されたSVGファイルのパス\n",
    "    \"\"\"\n",
    "    # WorkflowVizオブジェクトを作成\n",
    "    viz = WorkflowViz(workflow)\n",
    "    \n",
    "    # 3. SVGファイルとして保存\n",
    "    try:\n",
    "        svg_path = viz.export(format=\"svg\", filename=filename)\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"✅ SVGファイルを保存しました: {svg_path}\")\n",
    "        print(\"=\" * 60)\n",
    "        print()\n",
    "        \n",
    "        # 4. SVGをプレビュー表示\n",
    "        if show_preview and os.path.exists(svg_path):\n",
    "            display(SVG(filename=svg_path))\n",
    "        \n",
    "        return svg_path\n",
    "        \n",
    "    except ImportError as e:\n",
    "        print(\"❌ エラー: 'graphviz'パッケージがインストールされていません\")\n",
    "        print(\"インストール方法: pip install agent-framework[viz] --pre\")\n",
    "        print(f\"詳細: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ エラーが発生しました: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2498ae59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent Framework Workflow — 条件付きロジックを備えた順次実行\n",
    "from agent_framework import WorkflowBuilder, executor, WorkflowContext\n",
    "from typing_extensions import Never\n",
    "\n",
    "@executor(id=\"writer\")\n",
    "async def writer_exec(task: str, ctx: WorkflowContext[str]) -> None:\n",
    "    await ctx.send_message(f\"Draft: {task}\")\n",
    "\n",
    "@executor(id=\"reviewer\")\n",
    "async def reviewer_exec(draft: str, ctx: WorkflowContext[str]) -> None:\n",
    "    print(f\"reviewer: message: {draft}\")\n",
    "    decision = \"approve\" if \"solar\" in draft.lower() else \"revise\"\n",
    "    await ctx.send_message(f\"{decision}:{draft}\")\n",
    "\n",
    "@executor(id=\"editor\")\n",
    "async def editor_exec(msg: str, ctx: WorkflowContext[Never, str]) -> None:\n",
    "    print(f\"editor: message: {msg}\")\n",
    "    if msg.startswith(\"approve:\"):\n",
    "        await ctx.yield_output(msg.split(\":\", 1)[1])\n",
    "    else:\n",
    "        await ctx.yield_output(\"Needs revision\")\n",
    "\n",
    "workflow_seq = (\n",
    "    WorkflowBuilder()\n",
    "    .add_edge(writer_exec, reviewer_exec)\n",
    "    .add_edge(reviewer_exec, editor_exec)\n",
    "    .set_start_executor(writer_exec)\n",
    "    .build()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8386741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関数を使ってワークフローを可視化\n",
    "svg_path = visualize_workflow(\n",
    "    workflow_seq, \n",
    "    filename=\"sequential_conditional_workflow\",\n",
    "    show_preview=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b35b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"Workflow\") as rollspan: # ルートスパンを作成\n",
    "# 使用例（非同期コンテキスト内での使用例）\n",
    "    result = await workflow_seq.run(\"新しい発電方法としての solar energy の可能性についての記事を書いてください\")\n",
    "    result = await workflow_seq.run(\"新しい発電方法としての water energy の可能性についての記事を書いてください\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6cfe9b",
   "metadata": {},
   "source": [
    "#### 注目👀：型安全なメッセージルーティング\n",
    "- 入力型: ハンドラーの第一引数の型アノテーションから自動検出\n",
    "- 出力型: `ctx.send_message()` で送信するメッセージの型\n",
    "- ワークフロー出力型: `ctx.yield_output()` で返す最終結果の型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed05265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d3bcc8",
   "metadata": {},
   "source": [
    "### 1.2. Fan‑out + Fan-in\n",
    "並行処理パターンにおける **Fan-out (ファンアウト)** と **Fan-in (ファンイン/合流)** は、複数のタスクを並列実行し、その結果を統合する際の重要なパターンです。Agent Framework では、`add_fan_out_edges` と `add_fan_in_edges` が利用可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06ebf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "@executor(id=\"dispatcher\")\n",
    "async def dispatcher(task: str, ctx: WorkflowContext[str]) -> None:\n",
    "    await ctx.send_message(task)  # ← target_id 指定なし\n",
    "\n",
    "@executor(id=\"worker1\")\n",
    "async def worker1(text: str, ctx: WorkflowContext[str]) -> None:\n",
    "    await asyncio.sleep(2)\n",
    "    await ctx.send_message(f\"Worker1 result: {text}\")\n",
    "\n",
    "@executor(id=\"worker2\")\n",
    "async def worker2(text: str, ctx: WorkflowContext[str]) -> None:\n",
    "    await asyncio.sleep(5)\n",
    "    await ctx.send_message(f\"Worker2 result: {text}\")\n",
    "\n",
    "@executor(id=\"aggregator\")\n",
    "async def aggregator(results: list[str], ctx: WorkflowContext[Never, str]) -> None:\n",
    "    # FanInEdgeGroup が自動的にリストに集約\n",
    "    await ctx.yield_output(\"Aggregated: \" + \" | \".join(results))\n",
    "\n",
    "# Fan-out と Fan-in の組み合わせ\n",
    "wf_combined = (\n",
    "    WorkflowBuilder()\n",
    "    .add_fan_out_edges(dispatcher, [worker1, worker2])  # dispatcher → [worker1, worker2]\n",
    "    .add_fan_in_edges([worker1, worker2], aggregator)   # [worker1, worker2] → aggregator\n",
    "    .set_start_executor(dispatcher)\n",
    "    .build()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a0ad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関数を使ってワークフローを可視化\n",
    "svg_path = visualize_workflow(\n",
    "    wf_combined, \n",
    "    filename=\"fanout_fanin_workflow\",\n",
    "    show_preview=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7f980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"Workflow\") as rollspan: # ルートスパンを作成\n",
    "    result = await wf_combined.run(\"新しい発電方法としての solar energy の可能性についての記事を書いてください\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94311ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcf5242",
   "metadata": {},
   "source": [
    "**注目👀：実行フロー:**\n",
    "\n",
    "- `dispatcher` が `task` を1回送信\n",
    "- `FanOutEdgeGroup` が自動的に `worker1` と `worker2` に配信\n",
    "- Sleep 後、両方が完了\n",
    "- `FanInEdgeGroup` が結果を集約して `aggregator` を1回実行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a426b9",
   "metadata": {},
   "source": [
    "### 1.3. Targeted Routing (no broadcast)\n",
    "Targeted Routing は、Agent Framework のデータフロー型アーキテクチャにおける中核的な機能で、AutoGen のブロードキャスト方式とは根本的に異なるメッセージング戦略を採用しています。この機能により、メッセージを特定の宛先に直接送信することで、通信効率と予測可能性を大幅に向上させることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666167c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import WorkflowBuilder, executor, WorkflowContext\n",
    "from typing_extensions import Never\n",
    "\n",
    "@executor(id=\"ingest\")\n",
    "async def ingest(task: str, ctx: WorkflowContext[str]) -> None:\n",
    "    # Route selectively using target_id\n",
    "    if task.startswith(\"image:\"):\n",
    "        await ctx.send_message(task.removeprefix(\"image:\"), target_id=\"vision\")\n",
    "    else:\n",
    "        await ctx.send_message(task, target_id=\"writer\")\n",
    "\n",
    "@executor(id=\"writer\")\n",
    "async def write(text: str, ctx: WorkflowContext[Never, str]) -> None:\n",
    "    await ctx.yield_output(f\"Draft: {text}\")\n",
    "\n",
    "@executor(id=\"vision\")\n",
    "async def caption(image_ref: str, ctx: WorkflowContext[Never, str]) -> None:\n",
    "    await ctx.yield_output(f\"Caption: {image_ref}\")\n",
    "\n",
    "workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .add_edge(ingest, write)\n",
    "    .add_edge(ingest, caption)\n",
    "    .set_start_executor(ingest)\n",
    "    .build()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b56025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関数を使ってワークフローを可視化\n",
    "svg_path = visualize_workflow(\n",
    "    workflow, \n",
    "    filename=\"conditional_routing_workflow\",\n",
    "    show_preview=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195d344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"Workflow\") as rollspan: # ルートスパンを作成\n",
    "    # Example usage (async):\n",
    "    result = await workflow.run(\"Summarize the benefits of solar power\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7271d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20d0533",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"Workflow\") as rollspan: # ルートスパンを作成\n",
    "    # Example usage (async):\n",
    "    result = await workflow.run(\"image:https://example.com/panel.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e21b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6956172e",
   "metadata": {},
   "source": [
    "`WorkflowBuilder` と Executor を組み合わせることで、これまでに無かった自由度の高さと決定論的データフローを実現しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab91b924",
   "metadata": {},
   "source": [
    "\n",
    "## 2. ConcurrentBuilder\n",
    "並列オーケストレーションにより、複数のエージェントが同一タスクを並行して処理できます。各エージェントは入力を独立して処理し、その結果が集約されます。この手法は、ブレインストーミング、アンサンブル推論、投票システムなど、多様な視点や解決策が価値を持つシナリオに最適です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20177936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import ConcurrentBuilder, WorkflowOutputEvent\n",
    "\n",
    "agent1 = ChatAgent(\n",
    "    name=\"writer\",\n",
    "    chat_client=client,\n",
    "    instructions=\"あなたは創造的な小説家です。\"\n",
    ")\n",
    "\n",
    "agent2 = ChatAgent(\n",
    "    name=\"reviewer\",\n",
    "    chat_client=client,\n",
    "    instructions=\"あなたは創造的なレビュアーです。インプットされた小説を批判的に評価します。\"\n",
    ")\n",
    "\n",
    "agent3 = ChatAgent(\n",
    "    name=\"editor\",\n",
    "    chat_client=client,\n",
    "    instructions=\"あなたは細心の注意を払う編集者です。インプットされた小説を校正します。\"\n",
    ")\n",
    "\n",
    "# 並列処理のための並行ワークフロー\n",
    "workflow = (ConcurrentBuilder()\n",
    "           .participants([agent1, agent2, agent3])\n",
    "           .build())\n",
    "\n",
    "# 使用例（非同期コンテキスト内での使用例）\n",
    "async def concurrent_example():\n",
    "    with tracer.start_as_current_span(\"ConcurrentBuilder\") as rollspan: # ルートスパンを作成\n",
    "        # すべてのエージェントが入力を同時に処理する\n",
    "        async for event in workflow.run_stream(\"SEが異世界に転生して無双する話を書いてください\"):\n",
    "            if isinstance(event, WorkflowOutputEvent):\n",
    "                results = event.data  # 全エージェントからの統合結果\n",
    "\n",
    "                print(\"=== Concurrent Results ===\")\n",
    "                for i, res in enumerate(results):\n",
    "                    print(f\"Agent {i+1} result: {res.text}\")\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a98392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関数を使ってワークフローを可視化\n",
    "svg_path = visualize_workflow(\n",
    "    workflow, \n",
    "    filename=\"concurrent_workflow\",\n",
    "    show_preview=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7191bbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用例の実行\n",
    "await concurrent_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f2a7b2",
   "metadata": {},
   "source": [
    "トレースを見てすべてのエージェントが並列で処理されていることを確認してください。\n",
    "このシナリオを並列で処理してしまうと問題があることが分かります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2dc87a",
   "metadata": {},
   "source": [
    "**注目👀：内部で自動生成されるもの:**\n",
    "- ディスパッチャー (入力を各エージェントに配信)\n",
    "- 各エージェント用のラッパーExecutor\n",
    "- アグリゲーター (全結果を集約)\n",
    "- エッジ定義\n",
    "\n",
    "複数のエージェントに同じ入力を並列処理させたい、全エージェントの結果を単純に集約したい、素早くプロトタイプを作りたい、エージェント専用の並列処理を作りたい場合 `ConcurrentBuilder` が適しています。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862fc786",
   "metadata": {},
   "source": [
    "## 3. SequentialBuilder as Group Chat Patterns\n",
    "順次オーケストレーションでは、エージェントはパイプラインに組織化されます。各エージェントは順番にタスクを処理し、その出力をシーケンス内の次のエージェントに渡します。これは、文書レビュー、データ処理パイプライン、多段階推論など、各ステップが前のステップを基盤とするワークフローに理想的です。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833f4213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import SequentialBuilder, WorkflowOutputEvent\n",
    "from agent_framework import ChatAgent\n",
    "\n",
    "# 以前の例から、エージェント1、エージェント2、エージェント3があると仮定\n",
    "# Sequential workflow through participants\n",
    "workflow = SequentialBuilder().participants([agent1, agent2, agent3]).build()\n",
    "\n",
    "# 使用例（非同期コンテキスト内での使用例）\n",
    "async def sequential_example():\n",
    "    with tracer.start_as_current_span(\"SequentialBuilder\") as rollspan: # ルートスパンを作成\n",
    "        # 各エージェントは共有会話に追加する\n",
    "        async for event in workflow.run_stream(\"SEが異世界に転生して無双する話を書いてください\"):\n",
    "            if isinstance(event, WorkflowOutputEvent):\n",
    "                conversation_history = event.data  # list[ChatMessage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771cea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関数を使ってワークフローを可視化\n",
    "svg_path = visualize_workflow(\n",
    "    workflow, \n",
    "    filename=\"sequential_workflow\",\n",
    "    show_preview=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2455eb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "await sequential_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad33bb4",
   "metadata": {},
   "source": [
    "まぁ Group Chat パターンは Sequential フローですからね。。。この実装になると思います。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd785ed0",
   "metadata": {},
   "source": [
    "## 4. MagenticBuilder パターン\n",
    "Magentic オーケストレーションは、AutoGen が開発した Magentic-One システムに基づいて設計されています。これは、動的なコラボレーションを必要とする複雑でオープンエンドなタスク向けに設計された、柔軟で汎用的なマルチエージェントパターンです。このパターンでは、専任の Magentic マネージャーが専門エージェントのチームを調整し、変化するコンテキスト、タスクの進捗状況、エージェントの能力に基づいて、次にどのエージェントが行動すべきかを選択します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5b5075",
   "metadata": {},
   "source": [
    "![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/674344/17e098bb-aca8-48b5-87bb-4dcef3bef87c.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902ddf50",
   "metadata": {},
   "source": [
    "Magentic マネージャーは、共有コンテキストを維持し、進捗状況を追跡し、ワークフローをリアルタイムに適応させます。これにより、システムは複雑な問題を細分化し、サブタスクを委任し、エージェント間の連携を通じてソリューションを反復的に改良することが可能になります。このオーケストレーションは、解決策のパスが事前に不明で、複数回の推論、調査、DeepResearch、計算が必要となるシナリオに特に適しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ae1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import (\n",
    "    MagenticBuilder, MagenticCallbackMode, WorkflowOutputEvent,\n",
    "    MagenticCallbackEvent, MagenticOrchestratorMessageEvent, MagenticAgentDeltaEvent\n",
    ")\n",
    "\n",
    "researcher = ChatAgent(\n",
    "    name=\"researcher\",\n",
    "    chat_client=client,\n",
    "    instructions=\"You are a diligent researcher.\"\n",
    ")\n",
    "\n",
    "coder = ChatAgent(\n",
    "    name=\"coder\",\n",
    "    chat_client=client,\n",
    "    instructions=\"You are a skilled Python coder.\"\n",
    ")\n",
    "\n",
    "# 研究者、コーダー、およびクライアント調整役\n",
    "async def on_event(event: MagenticCallbackEvent) -> None:\n",
    "    if isinstance(event, MagenticOrchestratorMessageEvent):\n",
    "        print(f\"[ORCHESTRATOR]: {event.message.text}\")\n",
    "\n",
    "workflow = (MagenticBuilder()\n",
    "           .participants(researcher=researcher, coder=coder)\n",
    "           .on_event(on_event, mode=MagenticCallbackMode.STREAMING)\n",
    "           .with_standard_manager(\n",
    "               chat_client=client,\n",
    "               max_round_count=20,\n",
    "               max_stall_count=3,\n",
    "               max_reset_count=2\n",
    "           )\n",
    "           .build())\n",
    "\n",
    "# Example usage (would be in async context)\n",
    "async def magentic_example():\n",
    "    with tracer.start_as_current_span(\"MagenticBuilder\") as rollspan: # ルートスパンを作成\n",
    "        result = await workflow.run(\n",
    "            \"ブラックホールがどのように光を曲げるのかシミュレーションしたい。まず2Dで光線を描画するPythonコードを書いて。\",\n",
    "        )\n",
    "\n",
    "        print(\"\\n=== Magentic Final Result ===\")\n",
    "        print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40fc60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関数を使ってワークフローを可視化\n",
    "svg_path = visualize_workflow(\n",
    "    workflow, \n",
    "    filename=\"magentic_workflow\",\n",
    "    show_preview=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52107e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "await magentic_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0d91fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.get_outputs()[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e776a7eb",
   "metadata": {},
   "source": [
    "**注目👀：エージェントフレームワークのカスタマイズオプション:**\n",
    "- **マネージャー設定**: カスタムオーケストレーターモデルとプロンプト\n",
    "- **ラウンド制限**: `max_round_count`, `max_stall_count`, `max_reset_count`\n",
    "- **イベントコールバック**：詳細なイベントフィルタリングによるリアルタイムストリーミング\n",
    "- **エージェント特化**：エージェントごとのカスタム指示とツール\n",
    "- **コールバックモード**：STREAMING（リアルタイム更新用）または BATCH（最終結果用）\n",
    "- **Human-in-the-loop 計画**：対話型ワークフロー向けカスタムプランナー機能\n",
    "\n",
    "https://qiita.com/nohanaga/items/28fcf00a23e990ac3551\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca868e3c",
   "metadata": {},
   "source": [
    "### 🚧 将来のマルチエージェントパターン\n",
    "現在以下のエージェントは開発中です。\n",
    "\n",
    "- **Swarm**: ハンドオフベースのエージェントの調整\n",
    "- **SelectorGroupChat**: LLM 駆動スピーカーの選択"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7565ea2",
   "metadata": {},
   "source": [
    "## Workflow の可視化\n",
    "\n",
    "Agent Framework のワークフローは、データフローグラフとして可視化できます。これにより、エージェント間の接続や処理の流れを視覚的に理解できます。\n",
    "\n",
    "`WorkflowViz` ワークフローの可視化機能は、Workflow オブジェクトでインスタンス化できる `WorkflowViz` オブジェクトを通じて行われます。`WorkflowViz` オブジェクトは、Graphviz DOT 形式や Mermaid ダイアグラム形式など、様々な形式で可視化を生成できます。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b468d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ワークフローのグラフ構造を取得\n",
    "graph_info = workflow.to_dict()\n",
    "print(\"ワークフロー情報:\")\n",
    "import pprint\n",
    "pprint.pprint(graph_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac618d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import SequentialBuilder\n",
    "from agent_framework import (\n",
    "    WorkflowViz,\n",
    "    handler,\n",
    ")\n",
    "# 2) Build sequential workflow: writer -> reviewer\n",
    "workflow = SequentialBuilder().participants([agent1, agent2]).build()\n",
    "\n",
    "viz = WorkflowViz(workflow)\n",
    "# Print out the mermaid string.\n",
    "print(\"Mermaid string: \\n=======\")\n",
    "print(viz.to_mermaid())\n",
    "print(\"=======\")\n",
    "# Print out the DiGraph string.\n",
    "print(\"DiGraph string: \\n=======\")\n",
    "print(viz.to_digraph())\n",
    "print(\"=======\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2355d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Export the DiGraph visualization as SVG.\n",
    "    svg_file = viz.export(format=\"svg\", filename=\"sequential_workflow_diagram\")\n",
    "    print(f\"SVG file saved to: {svg_file}\")\n",
    "except ImportError:\n",
    "    print(\"Tip: Install 'viz' extra to export workflow visualization: pip install agent-framework[viz] --pre\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc73d959",
   "metadata": {},
   "source": [
    "## 5. ⭐️ Shared States\n",
    "Shared State により、ワークフロー内の複数の Executor が共通データにアクセスし、変更できるようになります。この機能は、ワークフローの複数の部分で情報を共有する必要があるものの、直接的なメッセージパッシングが実現不可能または効率的でないシナリオにおいて不可欠です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83124101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import WorkflowBuilder, executor, WorkflowContext\n",
    "from typing_extensions import Never\n",
    "\n",
    "# Executor 1: 共有状態にデータを保存\n",
    "@executor(id=\"setter\")\n",
    "async def setter_exec(input_data: str, ctx: WorkflowContext[str]) -> None:\n",
    "    # 共有状態にデータを保存\n",
    "    await ctx.set_shared_state(\"user_name\", \"田中太郎\")\n",
    "    await ctx.set_shared_state(\"age\", 30)\n",
    "    await ctx.set_shared_state(\"city\", \"東京\")\n",
    "    \n",
    "    print(\"✅ 共有状態に保存しました:\")\n",
    "    \n",
    "    await ctx.send_message(input_data)\n",
    "\n",
    "# Executor 2: 共有状態からデータを取得\n",
    "@executor(id=\"getter\")\n",
    "async def getter_exec(data: str, ctx: WorkflowContext[Never, str]) -> None:\n",
    "    # 共有状態からデータを取得\n",
    "    user_name = await ctx.get_shared_state(\"user_name\")\n",
    "    age = await ctx.get_shared_state(\"age\")\n",
    "    city = await ctx.get_shared_state(\"city\")\n",
    "    \n",
    "    print(\"\\n📥 共有状態から取得しました:\")\n",
    "    print(f\"  user_name: {user_name}\")\n",
    "    print(f\"  age: {age}\")\n",
    "    print(f\"  city: {city}\")\n",
    "    \n",
    "    result = f\"ユーザー情報: {user_name}さん、{age}歳、{city}在住\"\n",
    "    await ctx.yield_output(result)\n",
    "\n",
    "# ワークフロー構築\n",
    "workflow_shared_state = (\n",
    "    WorkflowBuilder()\n",
    "    .add_edge(setter_exec, getter_exec)\n",
    "    .set_start_executor(setter_exec)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# 実行\n",
    "result = await workflow_shared_state.run(\"テストデータ\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"🎯 最終結果:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aab9ce",
   "metadata": {},
   "source": [
    "## 6. ⭐️ Human-in-the-Loop with Request Response\n",
    "\n",
    "Agent Framework のワークフローの主な新機能は 、要求と応答の概念です。これにより、ワークフローは実行を一時停止し、外部入力を待ってから続行できます。AutoGen の Team 抽象化は開始されると継続的に実行され、人間の入力の実行を一時停止するための組み込みのメカニズムは提供されませんでした。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c72350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import (\n",
    "    RequestInfoExecutor, RequestInfoEvent, RequestInfoMessage,\n",
    "    RequestResponse, WorkflowBuilder, WorkflowContext, executor\n",
    ")\n",
    "from dataclasses import dataclass\n",
    "from typing_extensions import Never\n",
    "\n",
    "agent1 = ChatAgent(\n",
    "    name=\"idea_agent\",\n",
    "    chat_client=client,\n",
    "    instructions=\"あなたは創造的なアイデアライターです。\"\n",
    ")\n",
    "\n",
    "# Workflow executor that generates content\n",
    "@executor(id=\"writer\")\n",
    "async def agent_executor(\n",
    "    task: str,\n",
    "    ctx: WorkflowContext[str]\n",
    ") -> None:\n",
    "    response = await agent1.run(task)\n",
    "    await ctx.send_message(response.text)\n",
    "\n",
    "\n",
    "# Define typed request payload\n",
    "@dataclass\n",
    "class ApprovalRequest(RequestInfoMessage):\n",
    "    \"\"\"Request human approval for agent output.\"\"\"\n",
    "    content: str = \"\"\n",
    "    agent_name: str = \"\"\n",
    "\n",
    "# Workflow executor that requests human approval\n",
    "@executor(id=\"reviewer\")\n",
    "async def approval_executor(\n",
    "    agent_response: str,\n",
    "    ctx: WorkflowContext[ApprovalRequest]\n",
    ") -> None:\n",
    "    # Request human input with structured data\n",
    "    approval_request = ApprovalRequest(\n",
    "        content=agent_response,\n",
    "        agent_name=\"writer_agent\"\n",
    "    )\n",
    "    await ctx.send_message(approval_request)\n",
    "\n",
    "# Human feedback handler\n",
    "@executor(id=\"processor\")\n",
    "async def process_approval(\n",
    "    feedback: RequestResponse[ApprovalRequest, str],\n",
    "    ctx: WorkflowContext[Never, str]\n",
    ") -> None:\n",
    "    decision = feedback.data.strip().lower()\n",
    "    original_content = feedback.original_request.content\n",
    "\n",
    "    if decision == \"approve\":\n",
    "        await ctx.yield_output(f\"APPROVED: {original_content}\")\n",
    "    else:\n",
    "        await ctx.yield_output(f\"REVISION NEEDED: {decision}\")\n",
    "\n",
    "# Build workflow with human-in-the-loop\n",
    "hitl_executor = RequestInfoExecutor(id=\"request_approval\")\n",
    "\n",
    "workflow = (WorkflowBuilder()\n",
    "           .add_edge(agent_executor, approval_executor)\n",
    "           .add_edge(approval_executor, hitl_executor)\n",
    "           .add_edge(hitl_executor, process_approval)\n",
    "           .set_start_executor(agent_executor)\n",
    "           .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd90e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関数を使ってワークフローを可視化\n",
    "svg_path = visualize_workflow(\n",
    "    workflow, \n",
    "    filename=\"human_in_the_loop_workflow\",\n",
    "    show_preview=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9783bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage (would be in async context)\n",
    "with tracer.start_as_current_span(\"HumanInTheLoop_Workflow\") as rollspan: # ルートスパンを作成\n",
    "    result = await workflow.run(\n",
    "        \"SEが異世界に転生して無双する話を書いてください\",\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== HumanInTheLoop_Workflow Final Result ===\")\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad197f9",
   "metadata": {},
   "source": [
    "## Human-in-the-Loop ワークフローの実行\n",
    "Agent Framework には、一時停止再開サイクルを処理するためのストリーミング API が用意されています。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2ae587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import RequestInfoEvent, WorkflowOutputEvent\n",
    "\n",
    "# 以前の例から定義されたワークフローがあると仮定する\n",
    "async def run_with_human_input():\n",
    "    pending_responses = None\n",
    "    completed = False\n",
    "\n",
    "    while not completed:\n",
    "        # 最初の反復ではrun_streamを使用し、その後はsend_responses_streamingを使用する\n",
    "        stream = (\n",
    "            workflow.send_responses_streaming(pending_responses)\n",
    "            if pending_responses\n",
    "            else workflow.run_stream(\"initial input\")\n",
    "        )\n",
    "\n",
    "        events = [event async for event in stream]\n",
    "        pending_responses = None\n",
    "\n",
    "        # 人間の要求と出力を収集する\n",
    "        for event in events:\n",
    "            print(f\"イベント検知: {event}\")\n",
    "            if isinstance(event, RequestInfoEvent):\n",
    "                # 人間に要求を表示し、応答を収集する\n",
    "                request_data = event.data  # ApprovalRequest instance\n",
    "                print(f\"Review needed: {request_data.content}\")\n",
    "\n",
    "                human_response = input(\"Enter 'approve' or revision notes (or 'abort' to stop): \")\n",
    "                # 中断処理\n",
    "                if human_response.lower() == \"abort\":\n",
    "                    print(\"\\n🛑 ワークフローを中断しました\")\n",
    "                    completed = True\n",
    "                    break\n",
    "                \n",
    "                pending_responses = {event.request_id: human_response}\n",
    "\n",
    "            elif isinstance(event, WorkflowOutputEvent):\n",
    "                print(f\"Final result: {event.data}\")\n",
    "                completed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8524d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "await run_with_human_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c78ea7f",
   "metadata": {},
   "source": [
    "### 全体的な Human-in-the-Loop ワークフローの実行例\n",
    "\n",
    "[human-in-the-loop.py](./human-in-the-loop.py) をコンソールから実行してください。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36239bb",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "source": [
    "## 7. ⭐️ Checkpoint\n",
    "AutoGen の Team 抽象化に対する Agent Framework のワークフローのもう 1 つの主な利点は、**チェックポイント処理と実行の再開の組み込みサポート**です。 これにより、**ワークフローをチェックポイントから後で一時停止、永続化、再開できる**ため、フォールトトレランスが提供され、実行時間の長いワークフローまたは非同期ワークフローが有効になります。AutoGen の Team 抽象化では、組み込みのチェックポイント機能は提供されません。 永続化または回復メカニズムは外部で実装する必要があり、多くの場合、複雑な状態管理とシリアル化ロジックが必要です。\n",
    "\n",
    "\n",
    "### 7.1. エージェント フレームワークのチェックポイント処理\n",
    "Agent Framework では、`FileCheckpointStorage` と `WorkflowBuilder` の`with_checkpointing()` メソッドを使用した包括的なチェックポイント処理が提供されます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0597bac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import (\n",
    "    RequestInfoExecutor, FileCheckpointStorage, WorkflowBuilder, WorkflowOutputEvent,\n",
    "    Executor, WorkflowContext, handler\n",
    ")\n",
    "from typing_extensions import Never\n",
    "\n",
    "class UpperCaseExecutor(Executor):\n",
    "    @handler\n",
    "    async def process(self, text: str, ctx: WorkflowContext[str]) -> None:\n",
    "        result = text.upper()\n",
    "\n",
    "        # Executor固有の状態を永続化する\n",
    "        prev_state = await ctx.get_state() or {}\n",
    "        count = prev_state.get(\"count\", 0) + 1\n",
    "        await ctx.set_state({\n",
    "            \"count\": count,\n",
    "            \"last_input\": text,\n",
    "            \"last_output\": result\n",
    "        })\n",
    "\n",
    "        # 他のExecutor向けに共有状態を永続化する\n",
    "        await ctx.set_shared_state(\"original_input\", text)\n",
    "        await ctx.set_shared_state(\"processed_output\", result)\n",
    "\n",
    "        await ctx.send_message(result)\n",
    "\n",
    "class ReverseExecutor(Executor):\n",
    "    @handler\n",
    "    async def process(self, text: str, ctx: WorkflowContext[Never, str]) -> None:\n",
    "        result = text[::-1]\n",
    "        await ctx.yield_output(result)\n",
    "\n",
    "def create_workflow(checkpoint_storage: FileCheckpointStorage):\n",
    "    \"\"\"2つのExecutorとチェックポイント機能を備えたワークフローを作成する。\"\"\"\n",
    "    upper_executor = UpperCaseExecutor(id=\"upper\")\n",
    "    reverse_executor = ReverseExecutor(id=\"reverse\")\n",
    "\n",
    "    return (WorkflowBuilder()\n",
    "           .add_edge(upper_executor, reverse_executor)\n",
    "           .set_start_executor(upper_executor)\n",
    "           .with_checkpointing(checkpoint_storage=checkpoint_storage)\n",
    "           .build())\n",
    "\n",
    "checkpoint_storage = FileCheckpointStorage(storage_path=\"./checkpoints\")\n",
    "\n",
    "# 使用例（非同期コンテキスト内での使用例）\n",
    "async def checkpoint_example():\n",
    "    workflow = create_workflow(checkpoint_storage)\n",
    "    async for event in workflow.run_stream(\"Hello, Agent Framework!\"):\n",
    "        if isinstance(event, WorkflowOutputEvent):\n",
    "            print(f\"Output: {event.data}\")\n",
    "    return workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe06d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = await checkpoint_example()\n",
    "visualize_workflow(workflow, \"Checkpointing_Workflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38feb400",
   "metadata": {},
   "source": [
    "### 7.2. チェックポイントからの再開\n",
    "Agent Framework は、特定のチェックポイントを一覧表示、検査、再開するための API を提供します。以下のような 2 つの Executor を順次実行するシンプルなパイプラインを構築して実験してみましょう。\n",
    "\n",
    "1. 入力テキストを大文字化して次の処理へ渡す\n",
    "1. 受け取ったテキストを反転させて、ワークフローを完了させる\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40faba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用可能なチェックポイントの一覧\n",
    "checkpoints = await checkpoint_storage.list_checkpoints()\n",
    "\n",
    "# チェックポイント情報を表示する\n",
    "for checkpoint in checkpoints:\n",
    "    summary = RequestInfoExecutor.checkpoint_summary(checkpoint)\n",
    "    print(f\"Checkpoint {summary.checkpoint_id}: iteration={summary.iteration_count}\")\n",
    "    print(f\"  Shared state: {checkpoint.shared_state}\")\n",
    "    print(f\"  Executor states: {list(checkpoint.executor_states.keys())}\")\n",
    "    print(f\"  Messages: {checkpoint.messages}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43806137",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def checkpoint_resume_example():\n",
    "    # 特定のチェックポイントから再開する\n",
    "    if checkpoints:\n",
    "        chosen_checkpoint_id = checkpoints[0].checkpoint_id\n",
    "\n",
    "        # 新しいワークフローインスタンスを作成し、再開する\n",
    "        new_workflow = create_workflow(checkpoint_storage)\n",
    "        async for event in new_workflow.run_stream_from_checkpoint(\n",
    "            chosen_checkpoint_id,\n",
    "            checkpoint_storage=checkpoint_storage\n",
    "        ):\n",
    "            print(f\"Resumed event: {event}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd66f3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "await checkpoint_resume_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceaa540",
   "metadata": {},
   "source": [
    "**注目👀ポイント:**\n",
    "\n",
    "- `.with_checkpointing()` により、各スーパーステップ終了時に自動的に状態が保存される\n",
    "- `FileCheckpointStorage` がチェックポイントを JSON 形式でディスク(`./checkpoints`)に保存\n",
    "\n",
    "\n",
    "**再開の仕組み:**\n",
    "- `run_stream_from_checkpoint` が指定されたチェックポイントIDから状態を復元\n",
    "- 保存されていたメッセージキュー、Executor 状態、イテレーション数がすべて復元される\n",
    "- 中断した地点から処理が継続される\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5751c8",
   "metadata": {},
   "source": [
    "まず、1 番目の`upper` Executor を実行し、その状態をチェックポイントとして JSON で保存しておきます。その後、`FileCheckpointStorage` からロードしたチェックポイントをワークフローにロードして `run_stream_from_checkpoint` することで 1 番目の実行をスキップして 2番目の `reverse` から再開することができます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9888616d",
   "metadata": {},
   "source": [
    "### 高度なチェックポイント機能\n",
    "Human-in-the-Loop 統合を使用したチェックポイント:\n",
    "\n",
    "チェックポイント処理は、人間が入力するためにワークフローを一時停止し、後で再開できるように、ループ内の人間のワークフローとシームレスに機能します。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdac07c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume we have workflow, checkpoint_id, and checkpoint_storage from previous examples\n",
    "async def resume_with_responses_example():\n",
    "    # 事前に用意された人間の応答で再開する\n",
    "    responses = {\"request_id_123\": \"approved\"}\n",
    "    checkpoint_id = \"2b981805-60e9-4d03-9623-738c2140b524\"\n",
    "\n",
    "    async for event in workflow.run_stream_from_checkpoint(\n",
    "        checkpoint_id,\n",
    "        checkpoint_storage=checkpoint_storage,\n",
    "        responses=responses  # 人間のレスポンスを提供\n",
    "    ):\n",
    "        print(f\"Event: {event}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead5eda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "await resume_with_responses_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentfw1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
